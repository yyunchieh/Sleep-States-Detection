{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.1+cu124\n",
      "12.4\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import torch\n",
    "import pickle\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from evd.data import TimeseriesDataset\n",
    "from evd.model import LSTMModel\n",
    "from evd.training import trainer, EarlyStopping\n",
    "\n",
    "print(torch.__version__)  \n",
    "print(torch.version.cuda) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = 6> Data preprocessing </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading time: 138.77 secs.\n",
      "      series_id  step_x                 timestamp  anglez    enmo  event  \\\n",
      "0  038441c925bb       0  2018-08-14T15:30:00-0400  2.6367  0.0217      0   \n",
      "1  038441c925bb       1  2018-08-14T15:30:05-0400  2.6368  0.0215      0   \n",
      "2  038441c925bb       2  2018-08-14T15:30:10-0400  2.6370  0.0216      0   \n",
      "3  038441c925bb       3  2018-08-14T15:30:15-0400  2.6368  0.0213      0   \n",
      "4  038441c925bb       4  2018-08-14T15:30:20-0400  2.6368  0.0215      0   \n",
      "\n",
      "      _merge  \n",
      "0  left_only  \n",
      "1  left_only  \n",
      "2  left_only  \n",
      "3  left_only  \n",
      "4  left_only  \n",
      "[0 1 2]\n",
      "                  timestamp     series_id  event\n",
      "0  2018-08-14T15:30:00-0400  038441c925bb      0\n",
      "1  2018-08-14T15:30:05-0400  038441c925bb      0\n",
      "2  2018-08-14T15:30:10-0400  038441c925bb      0\n",
      "3  2018-08-14T15:30:15-0400  038441c925bb      0\n",
      "4  2018-08-14T15:30:20-0400  038441c925bb      0\n",
      "anglez    0\n",
      "enmo      0\n",
      "dtype: int64\n",
      "series_id    0\n",
      "step_x       0\n",
      "timestamp    0\n",
      "anglez       0\n",
      "enmo         0\n",
      "event        0\n",
      "_merge       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "data1 = pd.read_parquet(r'C:\\Users\\4019-tjyen\\Desktop\\child-mind-institute-detect-sleep-states\\train_series.parquet')\n",
    "data2 = pd.read_csv(r'C:\\Users\\4019-tjyen\\Desktop\\child-mind-institute-detect-sleep-states\\train_events.csv')\n",
    "\n",
    "merge_data = pd.merge(data1, data2, on=[\"series_id\",\"timestamp\"], how=\"left\", indicator=True)\n",
    "\n",
    "merge_data = merge_data.drop(columns=['night', 'step_y'])\n",
    "\n",
    "load_time = time.time()-start\n",
    "\n",
    "print('loading time: {:>6.2f} secs.'.format(load_time))\n",
    "\n",
    "merge_data[\"event\"].fillna(0, inplace=True)\n",
    "merge_data[\"event\"] = merge_data[\"event\"].replace({\"onset\": 1, \"wakeup\": 2})\n",
    "\n",
    "missing_values = merge_data.isnull().sum()\n",
    "\n",
    "\n",
    "print(merge_data.head())\n",
    "print(merge_data['event'].unique()) \n",
    "print(merge_data[[\"timestamp\", \"series_id\", \"event\"]].head())\n",
    "print(merge_data[[\"anglez\", \"enmo\"]].isnull().sum())\n",
    "print(missing_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "每一列的NaN數量：\n",
      " series_id    0\n",
      "step_x       0\n",
      "timestamp    0\n",
      "anglez       0\n",
      "enmo         0\n",
      "event        0\n",
      "_merge       0\n",
      "dtype: int64\n",
      "是否有NaN值： False\n"
     ]
    }
   ],
   "source": [
    "# 檢查是否有NaN值\n",
    "nan_check = merge_data.isna()\n",
    "\n",
    "# 查看每一列是否有NaN值的數量\n",
    "nan_count = nan_check.sum()\n",
    "\n",
    "# 查看是否有任何NaN值\n",
    "has_nan = nan_check.any().any()\n",
    "\n",
    "# 輸出結果\n",
    "print(\"每一列的NaN數量：\\n\", nan_count)\n",
    "print(\"是否有NaN值：\", has_nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     anglez      enmo\n",
      "0  0.322257 -0.192628\n",
      "1  0.322260 -0.194592\n",
      "2  0.322266 -0.193610\n",
      "3  0.322260 -0.196556\n",
      "4  0.322260 -0.194592\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "merge_data[[\"anglez\",\"enmo\"]] = scaler.fit_transform(merge_data[[\"anglez\", \"enmo\"]])\n",
    "print(merge_data[[\"anglez\",\"enmo\"]].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = 6> Selecting a subject </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "數量 6\n"
     ]
    }
   ],
   "source": [
    "individual_data = merge_data[merge_data['series_id']=='038441c925bb']\n",
    "#the numbers of features \n",
    "print(\"數量\", individual_data.shape[1] -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = 6> Setting hyperparameters </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = 128\n",
    "train_idx = 300000 ## First 300000 timesteps as training data and the rest as validation data\n",
    "\n",
    "input_dim = 4\n",
    "hidden_dim = 64\n",
    "num_layers = 3\n",
    "num_classes = 3\n",
    "batch_size = 128\n",
    "num_epochs = 100\n",
    "patience = 10\n",
    "\n",
    "lr = 0.005"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = 6> Setting GPU </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check GPU  \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "#x = torch.rand(1000, 1000, device=device)\n",
    "#y = torch.matmul(x, x)\n",
    "#print(y)  # 應在 GPU 上執行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\4019-tjyen\\AppData\\Local\\Temp\\ipykernel_23212\\568943879.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  individual_data['anglez_change'] = individual_data['anglez'] - individual_data['anglez'].shift(1)\n",
      "C:\\Users\\4019-tjyen\\AppData\\Local\\Temp\\ipykernel_23212\\568943879.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  individual_data['enmo_change'] = individual_data[\"enmo\"] - individual_data['enmo'].shift(1)\n",
      "C:\\Users\\4019-tjyen\\AppData\\Local\\Temp\\ipykernel_23212\\568943879.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  individual_data['enmo_change'].iloc[0] = 0\n",
      "C:\\Users\\4019-tjyen\\AppData\\Local\\Temp\\ipykernel_23212\\568943879.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  individual_data['anglez_change'].iloc[0] = 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      series_id  step_x                 timestamp    anglez      enmo  event  \\\n",
      "0  038441c925bb       0  2018-08-14T15:30:00-0400  0.322257 -0.192628      0   \n",
      "1  038441c925bb       1  2018-08-14T15:30:05-0400  0.322260 -0.194592      0   \n",
      "2  038441c925bb       2  2018-08-14T15:30:10-0400  0.322266 -0.193610      0   \n",
      "3  038441c925bb       3  2018-08-14T15:30:15-0400  0.322260 -0.196556      0   \n",
      "4  038441c925bb       4  2018-08-14T15:30:20-0400  0.322260 -0.194592      0   \n",
      "\n",
      "      _merge  anglez_change  enmo_change  \n",
      "0  left_only       0.000000     0.000000  \n",
      "1  left_only       0.000003    -0.001964  \n",
      "2  left_only       0.000006     0.000982  \n",
      "3  left_only      -0.000006    -0.002946  \n",
      "4  left_only       0.000000     0.001964  \n"
     ]
    }
   ],
   "source": [
    "#AngleZ change\n",
    "\n",
    "individual_data['anglez_change'] = individual_data['anglez'] - individual_data['anglez'].shift(1)\n",
    "\n",
    "#Enmo change\n",
    "\n",
    "individual_data['enmo_change'] = individual_data[\"enmo\"] - individual_data['enmo'].shift(1)\n",
    "\n",
    "individual_data['enmo_change'].iloc[0] = 0\n",
    "individual_data['anglez_change'].iloc[0] = 0\n",
    "\n",
    "print(individual_data.head())\n",
    "\n",
    "individual_data.to_csv(\"individual_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "source": [
    "<font size = 6> Datasets </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.tensor(individual_data[['anglez','enmo','anglez_change', 'enmo_change']].values, dtype=torch.float32)\n",
    "y = torch.tensor(individual_data['event'].values, dtype=torch.int64)\n",
    "\n",
    "\n",
    "train_dataset = TimeseriesDataset(X=X[:train_idx],\n",
    "                                  y=y[:train_idx],\n",
    "                                  seq_len=seq_len,\n",
    "                                  transform=None)\n",
    "\n",
    "valid_dataset = TimeseriesDataset(X=X[train_idx:],\n",
    "                                  y=y[train_idx:],\n",
    "                                  seq_len=seq_len,\n",
    "                                  transform=None)\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_dataset, \n",
    "                          batch_size = batch_size, \n",
    "                          drop_last=True,\n",
    "                          shuffle = True)\n",
    "\n",
    "valid_loader = DataLoader(valid_dataset, \n",
    "                          batch_size = batch_size, \n",
    "                          drop_last=True,\n",
    "                          shuffle = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save valid_loader\n",
    "with open('valid_loader.pkl', 'wb') as f:\n",
    "    pickle.dump(valid_loader, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = 6> Model </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTMModel(\n",
      "  (lstm): LSTM(4, 64, num_layers=3)\n",
      "  (fc): Linear(in_features=64, out_features=3, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = LSTMModel(input_dim=input_dim, hidden_dim=hidden_dim, num_layers=num_layers, num_classes=num_classes).to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = 6> Training </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "loss = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "early_stopping = EarlyStopping(patience=patience, verbose=True)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  14; valid iteration:  701; time:   0.71 secs; loss: 0.0050\n",
      " Early stopping triggered.\n",
      "\n",
      " Early stopping at epoch  14\n"
     ]
    }
   ],
   "source": [
    "trainer(num_epochs=num_epochs, \n",
    "        model=model, \n",
    "        loss=loss,\n",
    "        optimizer=optimizer,\n",
    "        train_loader=train_loader,\n",
    "        valid_loader=valid_loader,\n",
    "        early_stopping=early_stopping,\n",
    "        device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"train_model.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "umap_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
